{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**015017**\n",
        "**UMANG DHAR DWIVEDI**\n",
        "**HUGGING FACE PROJECTS**🤗\n",
        " \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   **Sentiment Analysis**\n",
        "2.   **ENGLISH - HINDI Translato**r\n",
        "3.   A**utomated Text Generator**\n",
        "\n"
      ],
      "metadata": {
        "id": "K7GMGqkVEoJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "****PART1 Sentiment Analysis****"
      ],
      "metadata": {
        "id": "Fbdcsavkg4cY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBpwkcn40z4m",
        "outputId": "7f098ec4-59d3-4173-a758-83d2b1e6b5fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.0.dev0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Transformers installation\n",
        "! pip install transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA55PnCf08j5",
        "outputId": "d5941244-785e-4c2d-dac1-ac28c6930ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline  # WE IMPORT PIPELINE FROM TRANSFORMERS, PIPELINE WILL BE CALLING A PRE TRAINED MODEL\n",
        "classifier = pipeline('sentiment-analysis')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vastia6GIB3b"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will be checking weather the sentiments we possess are carried out by the system\n"
      ],
      "metadata": {
        "id": "NOWtcZvBIC7m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y0lAu2D1KoU",
        "outputId": "46731092-4259-4ddf-a752-ae11abfbd2c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998819828033447}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "classifier('We are very happy .')   ##SHOULD HAVE A POSITIVE SENTIMET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrsIWPCc1cO7",
        "outputId": "56aca7f0-77ac-4b41-b796-1f72ddeadbf0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9988749623298645}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "classifier('We are very SAD .')    ##SHOULD HAVE A NEGATIVE SENTIMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHs-5LTo108A",
        "outputId": "10e39c30-e95a-4561-dc10-fe21b38f0c85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9606083035469055}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "classifier(\"we have been waiting for last 3 hours\") ##LET'S SEE IF WORKS SIMILARLY ON SITUATION ## SHOULD BE NEGATIVE "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-ha7LNf198z",
        "outputId": "fbe080f2-c699-4fa3-d85e-8676bef8bcb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9997585415840149}]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "classifier(\"we got the best seats\")  ##SHOULD BE POSITIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ZMiW6O_D2CHi"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "8A-fer0O2txQ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki15e5kP3Fea",
        "outputId": "59e011e9-1804-48b1-e9d3-82573a41bb7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juPL8_Nw3Jv5",
        "outputId": "fd55df3c-77e4-4c10-8da2-df99e83f4c30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '4 stars', 'score': 0.42292699217796326}]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "classifier(\"I am a good boy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"He is  a good teacher\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfSxpT6VbseS",
        "outputId": "7dcc4331-674f-4b72-aac8-db258ccf664a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '4 stars', 'score': 0.5031822919845581}]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"Spiderman was the best movie\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P61F6rcAdLVZ",
        "outputId": "9f6cda93-6389-475e-e0d9-d08be86c0fec"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '5 stars', 'score': 0.8448800444602966}]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"I don't like the movie\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z13Rg37Xc-Br",
        "outputId": "f5dd34d6-3d69-42ac-af0e-ecce198cef4e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '2 stars', 'score': 0.4483273923397064}]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"I hate the movie\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07SwWIxKdE43",
        "outputId": "d3bc8b84-0a00-4f8e-8143-314e2429accf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': '1 star', 'score': 0.7138820290565491}]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbykqkSh3VV0",
        "outputId": "e1b9a577-653b-4a7e-af97-f5d05f608004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_57']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "PPE0xjRZ342n"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(\"We are very happy to be present here with you all.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WxGAkw_3-BT",
        "outputId": "42132e91-2900-4960-dc5c-f2bb6aa79f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 2057, 2024, 2200, 3407, 2000, 2022, 2556, 2182, 2007, 2017, 2035, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "8IyB1mAP4CVl"
      },
      "outputs": [],
      "source": [
        "tf_batch = tokenizer(\n",
        "    [\"We are very happy to be present here with you all.\", \"We hope you don't hate it.\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"tf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnzLTKs14GOZ",
        "outputId": "faab1f26-de24-4700-cd0a-21f2f690d406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: [[101, 2057, 2024, 2200, 3407, 2000, 2022, 2556, 2182, 2007, 2017, 2035, 1012, 102], [101, 2057, 3246, 2017, 2123, 1005, 1056, 5223, 2009, 1012, 102, 0, 0, 0]]\n",
            "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]\n"
          ]
        }
      ],
      "source": [
        "for key, value in tf_batch.items():\n",
        "    print(f\"{key}: {value.numpy().tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "zfki_Ep04JY4"
      },
      "outputs": [],
      "source": [
        "tf_outputs = tf_model(tf_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tje8U5D4M2w",
        "outputId": "61cf1619-7332-4aa5-b7c4-381d90e4c752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "array([[-4.290483  ,  4.6060257 ],\n",
            "       [ 0.08181736, -0.04179246]], dtype=float32)>, hidden_states=None, attentions=None)\n"
          ]
        }
      ],
      "source": [
        "print(tf_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "6eqxJ1VW4PpN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7VaQCsy4T_J",
        "outputId": "ce080243-f856-4ab2-c1d6-a91739c02201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1.3684714e-04 9.9986315e-01]\n",
            " [5.3086317e-01 4.6913683e-01]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(tf_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "vdUaEiu54WbN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf_outputs = tf_model(tf_batch, labels = tf.constant([1, 0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "JNWGiU1L4Zlp"
      },
      "outputs": [],
      "source": [
        "tokenizer.save_pretrained('/content/drive/MyDrive/HUGGINGFACE') ##directory made to save in google drive\n",
        "model.save_pretrained('/content/drive/MyDrive/HUGGINGFACE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "IclrpGvE5HVL"
      },
      "outputs": [],
      "source": [
        "tf_outputs = tf_model(tf_batch, output_hidden_states=True, output_attentions=True)\n",
        "all_hidden_states, all_attentions = tf_outputs[-2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmoRmqPV5WZy",
        "outputId": "7382406d-ed87-44ba-cfd8-a1c0dddf3a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_77']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "EBxEEYz25aXQ"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertConfig, DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
        "config = DistilBertConfig(n_heads=8, dim=512, hidden_dim=4*512)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = TFDistilBertForSequenceClassification(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4O1zmt35jA8",
        "outputId": "3e189823-e106-4f83-c5d1-f9d2d40146e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_117', 'classifier', 'pre_classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertConfig, DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained(model_name, num_labels=10)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PART 2 TRANSLATION ENGLISH TO HINDI**"
      ],
      "metadata": {
        "id": "oselBoODhOMh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "5OAzsIMVTZOe"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -U -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "istXzi_Ddpol",
        "outputId": "f366614b-a153-4b97-e556-bee5b10b4447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ],
      "source": [
        "! pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua1eiCTIdwrw",
        "outputId": "247b52fe-ba36-44f2-f357-23668e4c65f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence-transformers==2.1.0\n",
            "transformers @ git+https://github.com/huggingface/transformers.git@6b655cc63fd7e8ec120d9c38321a286d04767db0\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iGIW9Zm4eHiC"
      },
      "outputs": [],
      "source": [
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UHuODToAeT24"
      },
      "outputs": [],
      "source": [
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KC5ngJ0IeW_m"
      },
      "outputs": [],
      "source": [
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_en = \"MY NAME IS UMANG , this is my project\""
      ],
      "metadata": {
        "id": "PkDfnicGgDhh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = tokenizer(article_en, return_tensors=\"pt\")\n"
      ],
      "metadata": {
        "id": "Pi6Cwu7wgOnT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# translate from English to Hindi\n",
        "generated_tokens = model.generate(\n",
        "    **model_inputs,\n",
        "    forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"]  ##hi_IN is the code to convert into hindi \n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "1E6MPYplgUQi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "wb7xkzgbgYuF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycoKtWZyghoi",
        "outputId": "3021a1f7-48a7-47b2-9345-ccaa565f3c46"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['मेरा नाम उमांग है, यह मेरी परियोजना है']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_en = \"I watched Spiderman last Saturday, it was no doubt one of the best movies. 3 spiderman on 1 screen was a delight expierence\""
      ],
      "metadata": {
        "id": "SEhl39FJiQXO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = tokenizer(article_en, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "nj1Soo5oiQAT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_tokens = model.generate(\n",
        "    **model_inputs,\n",
        "    forced_bos_token_id=tokenizer.lang_code_to_id[\"hi_IN\"]  ##hi_IN is the code to convert into hindi \n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "pDjY-uNQiPvq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "0WPUMxvCiPg3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTxR4QLAiPRk",
        "outputId": "1a25ad3c-f591-4bb4-ed7f-c9d034ab9cd4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['मैंने पिछले शनिवार को स्पाइडरमैन देखा था, इसमें कोई संदेह नहीं कि यह सर्वश्रेष्ठ फिल्मों में से एक था. एक स्क्रीन पर 3 स्पाइडरमैन एक आनंद था']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 3 TEXT GENERATOR"
      ],
      "metadata": {
        "id": "81OnYy02i5bE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zH2y4hvLi4Vv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from transformers import pipeline"
      ],
      "metadata": {
        "id": "ZDIg8CnViBgV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')  ## Model can be called through hugging face library by copying the name of model from the library"
      ],
      "metadata": {
        "id": "0h3vI2vbkro6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = generator(\" Superman vs Batman is \" , do_sample=True, min_length=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOZzeON7kmVI",
        "outputId": "57dbc2cc-f3be-4435-a72e-60a995d2f763"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg91sTckkwWW",
        "outputId": "e02bf5eb-011f-4577-c2a9-7c7e3a299bec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': ' Superman vs Batman is  an anime film made by Funimation from a script by Naoki Urasawa and Atsushi Kitamura which was released on July 27, 2010. The film is based on a character from the Japanese web site Comic Shop'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BROx0cHimsc_",
        "outputId": "036a4b00-38ba-4b1b-eded-e1549c1ed093"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Superman vs Batman is  an anime film made by Funimation from a script by Naoki Urasawa and Atsushi Kitamura which was released on July 27, 2010. The film is based on a character from the Japanese web site Comic Shop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = generator(\"import pandas as pd \\n import numpy as np\\n \" , do_sample=True, min_length=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmCj1XvlnuAH",
        "outputId": "a692f69f-3268-4f4c-d5bc-75957064f558"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FymBnSYQn_Y7",
        "outputId": "2dc81f88-1111-432b-f93c-221049b863aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'import pandas as pd \\n import numpy as np\\n \\n # Setup the dataframe of features, and the model\\n def make_dataset():\\n      \\n      # Create'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kR6RnypoF0y",
        "outputId": "c7e6eabb-0e08-4617-c8e7-0be359016b6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import pandas as pd \n",
            " import numpy as np\n",
            " \n",
            " # Setup the dataframe of features, and the model\n",
            " def make_dataset():\n",
            "      \n",
            "      # Create\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = generator(\"My name is Julien and I like to \" , do_sample=True, min_length=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhX2Rvx2oLR_",
        "outputId": "0348ed36-0e12-4dd0-9806-06961764baca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHOFxS2XoZTT",
        "outputId": "bacf7d1c-d842-43ca-ac3d-7b875b5e1bc8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'My name is Julien and I like to \\nwork hard.\\nMy goal is to make people smile.\\nI like to make people laugh.\\nI like to have a good time.\\nAnd you know what?\\nThe last thing'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbcwItjQodZz",
        "outputId": "73bdf9f4-aaa7-462b-b6cb-a76bc6083713"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is Julien and I like to \n",
            "work hard.\n",
            "My goal is to make people smile.\n",
            "I like to make people laugh.\n",
            "I like to have a good time.\n",
            "And you know what?\n",
            "The last thing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = generator(\"My name is Umang, my favorite \" , do_sample=True, min_length=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDqZ5fEdoj6C",
        "outputId": "d7fd8aaf-37b2-48c0-f2cd-24c12f47cb35"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S_xUrBjo15j",
        "outputId": "e6735eaf-6fb2-405e-ac2e-49b407f2351a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'My name is Umang, my favorite ichthyao, and I’m here to teach.”\\n\\nUmang, a middle-aged man, is the director of the International Center for Ichthyology. He has'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P3bJU04o8My",
        "outputId": "59d7324b-9428-44c1-91e4-e5f067566b52"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is Umang, my favorite ichthyao, and I’m here to teach.”\n",
            "\n",
            "Umang, a middle-aged man, is the director of the International Center for Ichthyology. He has\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NAnxeq6pk5NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THANKS**"
      ],
      "metadata": {
        "id": "aoB6CF8rk-Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YcWCxykelB34"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "F.A. PROJECT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}